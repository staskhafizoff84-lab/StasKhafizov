# Импортируем библиотеки и вспомогательные модули
import pandas as pd
from src import preprocess, models, utils

# 1. Загрузка данных
train_path = "../data/train.csv"
df = preprocess.load_data(train_path)

# 2. Первичный анализ
print(df.head())
print(df.info())
print(df.describe())

# 3. Преобразования (EDA)
# Распределение цены
import seaborn as sns, matplotlib.pyplot as plt
sns.histplot(df['trip_distance'], kde=True); plt.show()
sns.histplot(df['fare_amount'], kde=True); plt.show()

# Корреляция
corr = df.corr()['fare_amount'].sort_values(ascending=False)
print(corr)

# 4. Предобработка: pipeline
from sklearn.pipeline import Pipeline

numeric_features = ['trip_distance', 'hour', 'dayofweek',
                    'month', 'distance_km']   # добавим позже
categorical_features = []  # если есть, например, pickup_location_id

preprocessor = models.create_preprocessor(numeric_features,
                                         categorical_features)

# Добавляем новые признаки: расстояние по Haversine и время суток
df_ = preprocess.DistanceCalculator().transform(df)
df_ = preprocess.DateTimeFeatures('pickup_datetime').transform(df_)
df_['duration'] = df_['trip_duration']  # если есть

numeric_features.extend(['distance_km', 'duration'])

# Разделим на X, y
X = df_[numeric_features]
y = df_['fare_amount']

# Train‑validation split
from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42)

# 5. Обучение и сравнение моделей
model_dict = models.get_models()
results = []

for name, reg in model_dict.items():
    pipe = models.build_pipeline(preprocessor, reg)
    mae, r2 = models.evaluate_pipeline(pipe, X_train, y_train,
                                       X_val, y_val)
    results.append({'model': name, 'MAE': mae, 'R2': r2})
    print(f"{name:20} MAE={mae:.3f} R2={r2:.3f}")

# 6. Выбор лучшей модели
results_df = pd.DataFrame(results).sort_values('MAE')
print("\n--- Сравнение моделей ---")
print(results_df)

best_model_name = results_df.iloc[0]['model']
best_reg = model_dict[best_model_name]
best_pipe = models.build_pipeline(preprocessor, best_reg)
best_pipe.fit(X_train, y_train)
preds_val = best_pipe.predict(X_val)

# Оценка
from sklearn.metrics import mean_absolute_error, r2_score
print("\nЛучший пайплайн:", best_model_name)
print("MAE:", mean_absolute_error(y_val, preds_val))
print("R2 :", r2_score(y_val, preds_val))

# 7. Оптимизация XGBoost (если выбран)
if best_model_name == 'XGBRegressor':
    tuned_xgb = models.tune_xgb(X_train, y_train)
    print("\nЛучший XGB:", tuned_xgb.get_params())
    # пересобираем пайплайн
    best_pipe.set_params(regressor=tuned_xgb)

# 8. Сохранить лучшую модель
import joblib, pathlib
pathlib.Path("../results").mkdir(exist_ok=True)
joblib.dump(best_pipe, "../results/best_model.pkl")

# 9. Визуализация важности признаков (если применимо)
utils.plot_feature_importance(
    best_pipe.named_steps['regressor'],
    feature_names=numeric_features
)

# 10. Сохраняем предсказания на тестовой выборке, если есть
test_path = "../data/test.csv"
if pathlib.Path(test_path).exists():
    df_test = preprocess.load_data(test_path)
    # применяем те же трансформации
    df_test_ = preprocess.DistanceCalculator().transform(df_test)
    df_test_ = preprocess.DateTimeFeatures('pickup_datetime').transform(df_test_)
    X_test = df_test_[numeric_features]
    preds_test = best_pipe.predict(X_test)
    out = pd.DataFrame({'id': df_test['id'], 'fare_amount': preds_test})
    out.to_csv("../results/predictions.csv", index=False)
